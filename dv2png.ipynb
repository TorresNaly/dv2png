{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f252d2-b8d6-4909-985a-51fb20cec21b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FISH Image Converter-local (version 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7a69f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import shutil\n",
    "from smb.SMBConnection import SMBConnection\n",
    "import tempfile\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import tifffile\n",
    "import bigfish\n",
    "import bigfish.stack as stack\n",
    "import bigfish.plot as plot\n",
    "import bigfish.multistack as multistack\n",
    "import bigfish.detection as detection\n",
    "\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8b495",
   "metadata": {},
   "source": [
    "#### Input Image info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35f572a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input user info\n",
    "your_name = ''\n",
    "imaged_by = ''\n",
    "\n",
    "#specify the location of your data on the NAS\n",
    "input_directory = '' #/your/input/directory\n",
    "output_directory = '' #/your/output/directory\n",
    "\n",
    "#specify what you have in every channel\n",
    "Cy5 = \"\" # your 670 channel (asymmetric control)\n",
    "mCherry = \"\" # your 610 channel (query RNA)\n",
    "FITC = \"\" # your protein channel (protein markers)\n",
    "DAPI = \"\" \n",
    "\n",
    "# NAS credentials and connection information\n",
    "nas_host = '' #your_nas_server_hostname_or_ip'\n",
    "nas_user = '' #your_username\n",
    "nas_password = '' #your_password\n",
    "nas_share = '' #(specific for the O'Nishimura lab - edit accordingly)\n",
    "\n",
    "# Define which channels to include in the composite image\n",
    "include_channels = [Cy5, mCherry, FITC, DAPI]  # Modify this list to only include the channels you want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab9bf0-381c-46ed-a30b-bf23332a86a1",
   "metadata": {},
   "source": [
    "#### Connect to the NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ec442c-3af3-4abd-9c37-1098fd8be002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection is established.\n"
     ]
    }
   ],
   "source": [
    "experiment_ID = input_directory.split(os.path.sep)[-1]\n",
    "output_directory = os.path.join(output_directory, experiment_ID, 'images')\n",
    "\n",
    "\n",
    "# Connect to the NAS\n",
    "conn = SMBConnection(nas_user, nas_password, 'python-client', nas_host, use_ntlm_v2=True)\n",
    "conn.connect(nas_host, 445)\n",
    "\n",
    "# Check if connection is successfully established\n",
    "smb_directory_path = os.path.relpath(input_directory, f'/Volumes/{nas_share}')\n",
    "shared_files = conn.listPath(nas_share, smb_directory_path) # move into folder with raw data\n",
    "if shared_files:\n",
    "    print(\"Connection is established.\")\n",
    "else:\n",
    "    print(\"Connection is not established.\")\n",
    "    \n",
    "# #print the filenames, save in a list \n",
    "# filenames = [shared_file.filename for shared_file in shared_files if shared_file.filename.endswith((\"_R3D_D3D.dv\",\"_R3D_REF.dv\"))]\n",
    "# filenames = sorted(filenames)\n",
    "# filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae67898-a1ab-42ca-9ca1-a3170ad411cd",
   "metadata": {},
   "source": [
    "## <font color='red'>STOP!</font> Do not edit below this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff14853-fc24-47de-a50a-a00d3986684d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Code to read images directly from the NAS and save as a png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e98a2-73d9-4ad4-ad58-73b6f9fe699d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 List file paths and read image stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1314bcc-fe77-4b10-88a9-e27efd5db744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the color images and brightfield images in separate lists\n",
    "image_color_paths = []\n",
    "bf_paths = []\n",
    "\n",
    "for shared_file in shared_files:\n",
    "    file_path = os.path.join(input_directory, shared_file.filename) \n",
    "    if shared_file.filename.endswith(\"_R3D_D3D.dv\"):\n",
    "        # If it does, append it to the image_colors_paths list\n",
    "        image_color_paths.append(file_path)\n",
    "        image_color_paths = sorted(image_color_paths)\n",
    "    elif shared_file.filename.endswith(\"_R3D_REF.dv\"):\n",
    "        # If it ends with \"_R3D_REF.dv\", append it to the bf_paths list\n",
    "        bf_paths.append(file_path)\n",
    "        bf_paths = sorted(bf_paths)\n",
    "\n",
    "#Read all the image_color stacks and extract the image identifiers to save in \"subdirectories\"\n",
    "all_image_color_stacks = []\n",
    "subdirectories = []\n",
    "for image_color_path in image_color_paths:\n",
    "    image_color_stack = stack.read_dv(image_color_path, sanity_check=True)\n",
    "    all_image_color_stacks.append(image_color_stack)\n",
    "    file_name = os.path.splitext(os.path.basename(image_color_path))[0]\n",
    "    parts = file_name.split('_')\n",
    "    numeric_part = None\n",
    "    for i, part in enumerate(parts):\n",
    "        if part == 'R3D':\n",
    "            numeric_part = parts[i - 1]\n",
    "            break\n",
    "    if numeric_part is not None:\n",
    "        subdirectories.append(numeric_part)\n",
    "\n",
    "#Read all the bf stacks\n",
    "all_bf_stacks = []\n",
    "for bf_path in bf_paths:\n",
    "    bf_stack = stack.read_dv(bf_path, sanity_check=True)\n",
    "    all_bf_stacks.append(bf_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce6d1d-e55d-4d43-b4cf-5c20ce13a509",
   "metadata": {},
   "source": [
    "#### 1.2 Split channels, max project and save in image subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4bd8b8-ed81-4528-bc90-2f08452e34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 images saved as PNG in /Users/onishlab/Documents/01_bigfish/02_data/reports/231107_LP306_L4440/images\n"
     ]
    }
   ],
   "source": [
    "# # #List all the color images and brightfield images in separate lists\n",
    "# # Define which channels to include in the composite\n",
    "\n",
    "def normalize(img):\n",
    "    \"\"\"Normalize image to [0, 1] range.\"\"\"\n",
    "    return (img - img.min()) / (img.max() - img.min()) if img.max() > 0 else img\n",
    "\n",
    "# Iterate through all_image_color_stacks and extract channels\n",
    "all_color_channel_list = []\n",
    "for i, stack in enumerate(all_image_color_stacks):\n",
    "    image_colors = all_image_color_stacks[i]\n",
    "    \n",
    "    # Create subdirectory for outputs\n",
    "    output_subdirectory = os.path.join(output_directory, f\"{subdirectories[i]}\")\n",
    "    os.makedirs(output_subdirectory, exist_ok=True)\n",
    "    \n",
    "    # Store extracted channels for composite\n",
    "    channel_dict = {}\n",
    "\n",
    "    # Extract and save individual channels\n",
    "    for channel_index in range(image_colors.shape[0]):\n",
    "        current_image = image_colors[channel_index, :, :]\n",
    "        all_color_channel_list.append(current_image)\n",
    "\n",
    "        # Dynamically assign channel names\n",
    "        channel_name = None\n",
    "        if channel_index == 0:\n",
    "            channel_name = Cy5\n",
    "        elif channel_index == 1:\n",
    "            channel_name = mCherry\n",
    "        elif channel_index == 2:\n",
    "            channel_name = FITC\n",
    "        elif channel_index == 3:\n",
    "            channel_name = DAPI\n",
    "\n",
    "        # Save each channel image (max projection in z-axis for 3D)\n",
    "        max_projection = np.max(current_image, axis=0)  # Take max projection along z-axis\n",
    "        plot_filename = os.path.join(output_subdirectory, f\"{subdirectories[i]}_{channel_name}_deconvolved.png\")\n",
    "        plt.imsave(plot_filename, max_projection, cmap='gray')\n",
    "\n",
    "        # Show the individual channel (for debugging/visualization)\n",
    "        # plt.figure(figsize=(6, 6))\n",
    "        # plt.imshow(max_projection, cmap='gray')\n",
    "        # plt.title(f\"{channel_name} Channel\")\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "        # Store channel for composite if selected\n",
    "        if channel_name in include_channels:\n",
    "            # Normalize and add to dictionary\n",
    "            channel_dict[channel_name] = normalize(max_projection)  # Normalize the selected channels\n",
    "\n",
    "    # Apply a scaling factor to increase visibility\n",
    "    scale_factor = 2.0  # Adjust this value to see if it helps\n",
    "\n",
    "    # Create composite image if selected channels exist\n",
    "    if channel_dict:\n",
    "        # Ensure all channels are the same size\n",
    "        if len(set([img.shape for img in channel_dict.values()])) > 1:\n",
    "            print(f\"Warning: The images for {', '.join(channel_dict.keys())} have mismatched sizes.\")\n",
    "            continue  # Skip this stack if sizes don't match\n",
    "\n",
    "        # Initialize the composite image (RGB, 3 channels)\n",
    "        composite = np.zeros((channel_dict[next(iter(channel_dict))].shape[0], \n",
    "                             channel_dict[next(iter(channel_dict))].shape[1], 3))  # Initialize RGB image\n",
    "\n",
    "        # Assign colors based on selected channels\n",
    "        # Normalize and apply scaling factor to each channel before combining them\n",
    "        if Cy5 in channel_dict:\n",
    "            cy5_channel = normalize(channel_dict[Cy5]) * scale_factor  # Normalize and scale Cy5 channel\n",
    "            composite[..., 0] = np.maximum(composite[..., 0], cy5_channel)  # Max red intensity for Cy5\n",
    "\n",
    "        if mCherry in channel_dict:\n",
    "            mcherry_channel = normalize(channel_dict[mCherry]) * scale_factor  # Normalize and scale mCherry channel\n",
    "            composite[..., 0] = np.maximum(composite[..., 0], mcherry_channel)  # Max red intensity for mCherry\n",
    "            composite[..., 2] = np.maximum(composite[..., 2], mcherry_channel)  # Max blue intensity for mCherry\n",
    "            # This creates the magenta effect: red + blue\n",
    "\n",
    "        if FITC in channel_dict:\n",
    "            fitc_channel = normalize(channel_dict[FITC])  # Normalize FITC channel\n",
    "            composite[..., 1] = np.maximum(composite[..., 1], fitc_channel)  # Max green intensity for FITC\n",
    "\n",
    "        if DAPI in channel_dict:\n",
    "            dapi_channel = normalize(channel_dict[DAPI])  # Normalize DAPI channel\n",
    "            composite[..., 2] = np.maximum(composite[..., 2], dapi_channel)  # Max blue intensity for DAPI\n",
    "\n",
    "        # Normalize the final composite image to the [0, 1] range\n",
    "        composite = np.clip(composite / composite.max(), 0, 1) if composite.max() > 0 else composite\n",
    "\n",
    "        # Apply brightness adjustment after composite is made (adjust to taste)\n",
    "        brightness_factor = 2  # Adjust this value for brightness\n",
    "        composite = np.clip(composite * brightness_factor, 0, 1)  # Apply brightness increase\n",
    "\n",
    "        # Save the composite image\n",
    "        composite_filename = os.path.join(output_subdirectory, f\"{subdirectories[i]}_composite.png\")\n",
    "        plt.imsave(composite_filename, composite)\n",
    "\n",
    "        # Show the composite image (for debugging/visualization)\n",
    "        # plt.figure(figsize=(6, 6))\n",
    "        # plt.imshow(composite)\n",
    "        # plt.title(\"Composite Image\")\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "print(f\"{len(subdirectories)} images saved as PNG in {output_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c8690-9659-4652-8ffe-a5d2eb360365",
   "metadata": {},
   "source": [
    "#### 1.3 Generate pdf report with deconvolved images (as .png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b428a5-0b85-43ee-b2a4-fbb810a1c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF report created: /Users/onishlab/Documents/01_bigfish/02_data/reports/231107_LP306_L4440/images/report.pdf\n"
     ]
    }
   ],
   "source": [
    "# Generate report\n",
    "# Define the desired order of the images on the pdf report\n",
    "image_order = [Cy5, mCherry, FITC, DAPI, \"composite\"]\n",
    "\n",
    "# Function to generate the cover letter\n",
    "def add_cover_letter(experiment_details, readme_content):\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=14)\n",
    "    pdf.cell(100, 10, txt=(f\"Experiment Title: {experiment_ID}\"), ln=True, align='C')\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # Add experiment details\n",
    "    for detail in experiment_details:\n",
    "        pdf.cell(200, 10, txt=detail, ln=True, align='L')\n",
    "    \n",
    "    pdf.ln(5)\n",
    "\n",
    "    # Add README content\n",
    "    pdf.multi_cell(0, 10, txt=readme_content)\n",
    "    pdf.ln(10)\n",
    "\n",
    "# Create a PDF report\n",
    "pdf_filename = os.path.join(output_directory, \"report.pdf\")\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "# Find the file that ends with \"README\"\n",
    "readme_file = None\n",
    "for file_path in glob.glob(os.path.join(input_directory, '*README.*')):\n",
    "    readme_file = file_path\n",
    "    break\n",
    "\n",
    "if readme_file:\n",
    "    # Read README content\n",
    "    with open(readme_file, \"r\") as file:\n",
    "        readme_content = file.read()\n",
    "else:\n",
    "    readme_content = \"No README file found.\"\n",
    "\n",
    "# Add cover letter once at the beginning\n",
    "today_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "add_cover_letter([f\"Date of processing: {today_date}\",\n",
    "                  f\"Imaged by: {imaged_by}\",\n",
    "                  f\"Processed by: {your_name}\",\n",
    "                  f\"channels: {image_order}\",\n",
    "                  f\"channels in composite: {include_channels}\",\n",
    "                  \" \",\n",
    "                  \"Readme file:\"], readme_content)\n",
    "\n",
    "# Add a single page for all images\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "# Iterate through subdirectories and add images\n",
    "for subdirectory in sorted(subdirectories):\n",
    "    # Add experiment title and image ID\n",
    "    pdf.cell(200, 10, txt=f\"Image ID: {experiment_ID}_{subdirectory}\", ln=True, align='L')\n",
    "    pdf.ln(5)\n",
    "\n",
    "    # Get PNG files in the subdirectory\n",
    "    subdirectory_path = os.path.join(output_directory, subdirectory)\n",
    "    png_files = glob.glob(os.path.join(subdirectory_path, '*.png'))\n",
    "\n",
    "    # Sort PNG files according to the desired image order\n",
    "    png_files_sorted = sorted(png_files, key=lambda x: image_order.index(os.path.basename(x).split('_')[1]) if os.path.basename(x).split('_')[1] in image_order else len(image_order))\n",
    "\n",
    "    # Calculate the number of columns that can fit on the page\n",
    "    max_columns = 5  # You can adjust this value based on your preference\n",
    "    num_columns = min(len(png_files_sorted), max_columns)\n",
    "\n",
    "    # Calculate the width of each column\n",
    "    column_width = 190 / num_columns\n",
    "\n",
    "    # Add images to the PDF in columns with space between images\n",
    "    for i, png_file in enumerate(png_files_sorted):\n",
    "        x_position = pdf.get_x() + i % num_columns * column_width\n",
    "        y_position = pdf.get_y() + int(i / num_columns) * 20  # Adjust space between rows\n",
    "\n",
    "        pdf.image(png_file, x=x_position, y=y_position, w=column_width)\n",
    "    \n",
    "    pdf.ln(80 * ((len(png_files_sorted) - 1) // num_columns + 1))  # Adjust line height based on the number of rows\n",
    "\n",
    "# Output the PDF file\n",
    "pdf.output(pdf_filename)\n",
    "print(f\"PDF report created: {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db453c-e474-48e7-a3de-ff74239335b6",
   "metadata": {},
   "source": [
    "### Code by Naly Torres. Last edited Jan. 30th, 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
